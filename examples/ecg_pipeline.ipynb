{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BIOBSS - ECG Pipeline__\n",
    "\n",
    "_This notebook includes guidelines to help using pipeline module for ECG signal processing and feature extraction._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import BIOBSS and other required packages\n",
    "\n",
    "import biobss\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [ECG Sample Data](#sampledata)<br>\n",
    "2. [Peak Detection](#ppg_peak)<br>\n",
    "3. [Create Bio Process Objects](#create_bioprocess)<br>\n",
    "4. [Create Feature Objects](#create_feature)<br>\n",
    "5. [Create Bio Pipeline Object](#create_pipeline)<br>\n",
    "6. [Create Bio Channel Objects](#create_biochannel)<br>\n",
    "7. [Set Pipeline Inputs](#set_input)<br>\n",
    "8. [Add Bio Process Objects to Pipeline](#add_bioprocess)<br>\n",
    "9. [Add Feature Objects to Pipeline](#add_feature)\n",
    "10. [Run Pipeline](#run_pipeline)<br>\n",
    "11. [Extract Features](#extract_features)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __ECG Sample Data__\n",
    "<a id=\"sampledata\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ECG sample data is provided as a csv file in BIOBSS\\sample data. The data file contains an ECG signal of 5 minutes length, sampled at 256 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the sample data\n",
    "data, info = biobss.utils.load_sample_data(data_type='ECG')\n",
    "sig = np.asarray(data['ECG'])\n",
    "fs = info['sampling_rate']\n",
    "L = info['signal_length']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Peak Detection__\n",
    "<a id=\"ecg_peak\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIOBSS provides a specialized peak detection function for ECG signal. The function uses 'ecgdetectors' package to implement methods and returns a dictionary of R-peak locations and amplitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect peaks using 'pantompkins' method.\n",
    "locs_peaks=biobss.ecgtools.ecg_peaks(sig,fs,'pantompkins')\n",
    "peaks = sig[locs_peaks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Delineation__\n",
    "<a id=\"ecg_waves\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since ECG signal has a complex waveform including P wave, QRS complex and T wave; BIOBSS also provides a delineation function. This function uses 'neurokit2' method from Neurokit2 package and returns a dictionary of all fiducial locations. The function requires R-peak locations to calculate the fiducial locations. If peaks_locs is not provided, the function calculates the locations itself using 'pantompkins' method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delineate ECG signal using 'neurokit2' method. \n",
    "\n",
    "fiducials = biobss.ecgtools.ecg_waves(sig=sig, sampling_rate=fs, delineator='neurokit2')\n",
    "\n",
    "p_peaks_locs = fiducials['ECG_P_Peaks']\n",
    "q_peaks_locs = fiducials['ECG_Q_Peaks']\n",
    "s_peaks_locs = fiducials['ECG_S_Peaks']\n",
    "t_peaks_locs = fiducials['ECG_T_Peaks']\n",
    "p_onset_locs = fiducials['ECG_P_Onsets']\n",
    "t_offset_locs = fiducials['ECG_T_Offsets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Create Bio Process Objects__\n",
    "<a id=\"create_bioprocess\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any process can be added to the pipeline if the input is a signal and ouput is a signal or collection of signals. The process can be added by passing the method to a Bio_Process constructor. The Bio_Process constructor takes the following arguments:\n",
    "\n",
    "- process_method: The method to be added to the pipeline\n",
    "- inplace: If True, result of the process will modify the input signal. If False, the result of the process will be returned as a new signal and added as a new channel.\n",
    "- prefix: The prefix to be added to the output channel name. If inplace is True, prefix will be ignored.\n",
    "  - If inplace is False, the output channel name will be prefix + input channel name.\n",
    "  - <code> (Default: None) (if inplace = False  and prefix = None, prefix will be set to 'processed') </code>\n",
    "- return_index : If a return_index is set, selected index of the result will be set as result. If return_index is None, the whole result will be set as result. (Default: None)\n",
    "- argmap: this dictionary maps different named arguments. For example, Bio_Channel already have a sampling_rate attribute. If the process method requires sampling rate with a different name, it can be mapped to the Bio_Channel attribute.<code> EXAMPLE : argmap = {'sampling_rate': 'fs'} or argmap = {'sampling_rate': 'sample_rate'} </code>\n",
    "- **kwargs: Keyword arguments to be passed to the process method\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Pipeline processes the given input sequentially. The input is passed from one process to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create steps for the pipeline\n",
    "\n",
    "# Filter steps process,return filtered signal for all input signals\n",
    "clean=biobss.pipeline.Bio_Process(\n",
    "    process_method=biobss.ecgtools.filter_ecg, argmap={\"sampling_rate\":\"sampling_rate\"}, sampling_rate=fs)\n",
    "\n",
    "# Signal normalization step, return normalized signal for all input signals\n",
    "normalize = biobss.pipeline.Bio_Process(\n",
    "    process_method=biobss.preprocess.normalize_signal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='Green'>__Create Feature Objects__ </font>\n",
    "<a id=\"create_feature\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Red'>The cell below should be modified after resolving the discrete input issue. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature extraction steps\n",
    "\n",
    "# Extract time domain features. input_signals dictionary contains feature prefixes as keys and input signals as values\n",
    "# For example rms of EDA_Tonic is extracted as Tonic_rms in this case\n",
    "Rpeak_features = biobss.pipeline.Feature(name=\"time_features\", function=biobss.ecgtools.from_Rpeaks, input_signals={'ECG_Raw':'ECG_Raw'}, sampling_rate=fs, argmap={'sampling_rate':'sampling_rate'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Create Bio Pipeline Object__\n",
    "<a id=\"create_pipeline\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIOBSS Pipeline is created\n",
    "# windowed_process=True means that the pipeline will process the signal in windows\n",
    "# window_size=60 means that the pipeline will process 60 seconds of data at a time\n",
    "# step_size=20 means signal will be shifted by 20 seconds for each window\n",
    "pipeline = biobss.pipeline.Bio_Pipeline(windowed_process=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Create Bio Channel Objects__\n",
    "<a id=\"create_biochannel\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input is created as Bio_Channel object\n",
    "# Bio_Channel object requires following parameters: name, signal, sampling_rate\n",
    "# Optionally timestamp can be provided\n",
    "# If timestamp is provided, resolution of the timestamp should be provided. Possible resolutions are:'min', 's', 'ms', 'us'\n",
    "# If timestamp is not provided, timestamp will be created using sampling_rate. Default resolution is 's'\n",
    "bio_channel=biobss.pipeline.Bio_Channel(signal=sig,name=\"ECG_Raw\",sampling_rate=fs)\n",
    "\n",
    "# a Bio Channel object is created with sample data, with the name EDA_Raw and sampling rate 700\n",
    "# timestamp is not provided, so timestamp will be created using sampling_rate\n",
    "\n",
    "# Simply bio_channel the channel object will print the channel properties\n",
    "bio_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bio_channel.channel accesses the data in the channel object\n",
    "bio_channel.channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Set Pipeline Inputs__\n",
    "<a id=\"set_input\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline input can be set from an array, a dataframe, pandas series, list, Bio_Channel, Bio_Data\n",
    "\n",
    "# In this case, the pipeline input is set with an array\n",
    "pipeline.set_input(sig,sampling_rate=fs,name='ECG_Raw')\n",
    "\n",
    "# Alternatively, the pipeline input can be set with a Bio_Channel object, in this case the name and sampling rate are not required as they are already provided in the Bio_Channel object\n",
    "pipeline.set_input(bio_channel)\n",
    "\n",
    "pipeline.input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Add Bio Process Objects to Pipeline__\n",
    "<a id=\"add_bioprocess\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline steps are added to the pipeline sequentially, the order of the steps is important as the output of one step is the input of the next step\n",
    "# These steps will be processed in the order they are added to the pipeline\n",
    "pipeline.preprocess_queue.add_process(clean)\n",
    "pipeline.preprocess_queue.add_process(normalize)\n",
    "\n",
    "\n",
    "# Currently all the steps are added to the preprocess_queue\n",
    "# After the preprocess_queue is processed, data will be segmented into windows (if windowed_process=True)\n",
    "# For running process in windows, the process_queue is used\n",
    "\n",
    "## This structure will change in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Add Feature Objects to Pipeline__\n",
    "<a id=\"add_feature\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features are added to the pipeline\n",
    "pipeline.add_feature_step(Rpeak_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represetation of the pipeline\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Run Pipeline__\n",
    "<a id=\"run_pipeline\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline is run, this will process the input data in the pipeline\n",
    "pipeline.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represetation of the pipeline data after running\n",
    "pipeline.data\n",
    "\n",
    "# Data is cleaned\n",
    "# Data is normalized\n",
    "# Data is decomposed into tonic and phasic components, these componenets are added to the pipeline data as EDA_Tonic and EDA_Phasic channels\n",
    "# Lastly, data is resampled to 350Hz (All channels are resampled to 350Hz) (target_sample_rate=350)\n",
    "# Data is segmented into windows of 60 seconds with a step size of 20 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Extract Features__\n",
    "<a id=\"extract_features\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical and signal features are extracted from the EDA_Tonic, EDA_Phasic and EDA_Raw channels\n",
    "# Supplied prefix is added to the feature name\n",
    "pipeline.extract_features()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represetation of the pipeline features after extraction\n",
    "# Each row is a feature vector for a window\n",
    "# index is the timestamp of the window (this can be selected as start, end or center of the window)\n",
    "pipeline.features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biobss_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0 (default, Nov  6 2019, 16:00:02) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2da08f22468fb3696c83331e9a8c56525a02dc4129e32fd96f2f3d0a3b229d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
